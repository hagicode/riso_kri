import streamlit as st
import streamlit.components.v1 as stc
import pandas as pd
import numpy as np
import glob
import pathlib
import os
import io
import plotly.io as pio
from io import StringIO, BytesIO
import base64
import pickle
from streamlit_gsheets import GSheetsConnection

#æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€è¨ˆç®—ãªã©ã‚’ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã‚‚ã®
from yahoo_finance_api2 import share
from yahoo_finance_api2.exceptions import YahooFinanceError
import pandas as pd



#ç”»åƒç·¨é›†ã«å¿…è¦ãªã‚‚ã®
from PIL import Image
from PIL import ImageFont
from PIL import ImageDraw


#æ—¥ä»˜ãªã©ã®å–å¾—
import time
import datetime

import google_auth_httplib2
import httplib2
import streamlit as st
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import HttpRequest

SCOPE = "https://www.googleapis.com/auth/spreadsheets"
SHEET_ID = "1vXaglvGGbGN0pc8vEjiA7bCPpPTacFxvLGm3iKRVVUw"
SHEET_NAME = "ã‚·ãƒ¼ãƒˆ1"

@st.experimental_singleton()
def connect_to_gsheet():
    # Create a connection object
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"], scopes=[SCOPE]
    )

    # Create a new Http() object for every request
    def build_request(http, *args, **kwargs):
        new_http = google_auth_httplib2.AuthorizedHttp(
            credentials, http=httplib2.Http()
        )

        return HttpRequest(new_http, *args, **kwargs)

    authorized_http = google_auth_httplib2.AuthorizedHttp(
        credentials, http=httplib2.Http()
    )

    service = build("sheets", "v4", requestBuilder=build_request, http=authorized_http)
    gsheet_connector = service.spreadsheets()

    return gsheet_connector

def overwrite_gsheet_with_df(gsheet_connector, df: pd.DataFrame):
    # Convert the DataFrame to a list of lists
    data = df.values.tolist()

    # Clear the existing data in the sheet
    gsheet_connector.values().clear(
        spreadsheetId=SHEET_ID,
        range=SHEET_NAME,
    ).execute()

    # Write the new data to the sheet
    gsheet_connector.values().update(
        spreadsheetId=SHEET_ID,
        range=f"{SHEET_NAME}!A1",
        body=dict(values=data),
        valueInputOption="USER_ENTERED",
    ).execute()


def cal_data_min(symbols,chart_type):

    #æŒ‡å®šã—ãŸéŠ˜æŸ„ã®åˆ†è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—
    my_data = share.Share(str(symbols)+".T")
    symbol_data = None
    if chart_type == "1min":#7æ—¥é–“
        _dayRange = 7
        _min = 1
        symbol_data = my_data.get_historical(share.PERIOD_TYPE_DAY,_dayRange,share.FREQUENCY_TYPE_MINUTE,_min)
    if chart_type == "5min":
        _dayRange = 60
        _min = 5
        symbol_data = my_data.get_historical(share.PERIOD_TYPE_DAY,_dayRange,share.FREQUENCY_TYPE_MINUTE,_min)

    if chart_type == "15min":
        _minRange = 60
        _min = 15
        symbol_data = my_data.get_historical(share.PERIOD_TYPE_DAY,_minRange,share.FREQUENCY_TYPE_MINUTE,_min)

    if chart_type == "1hour":#730æ—¥é–“
        _monthRange = 24
        _min = 60
        symbol_data = my_data.get_historical(share.PERIOD_TYPE_MONTH,_monthRange,share.FREQUENCY_TYPE_MINUTE,_min)

    if chart_type == "1d":
        _yearRange = 25
        _day = 1
        symbol_data = my_data.get_historical(share.PERIOD_TYPE_YEAR,_yearRange,share.FREQUENCY_TYPE_DAY, _day)


    #åŠ å·¥ã§ãã‚‹å½¢ã«ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’å¤‰æ›´
    df = pd.DataFrame(symbol_data)
    df["datetime"] = pd.to_datetime(df.timestamp, unit="ms")

    #timestampã‚’æ—¥æœ¬æ™‚é–“ã¸å¤‰æ›
    df["datetime_jst"] = df["datetime"] + datetime.timedelta(hours=9)
    df["datetime"] = df["datetime"].astype(str)
    df["datetime_jst"] = df["datetime_jst"].astype(str)

    #ãƒ‡ãƒ¼ã‚¿å–å¾—ã§ãã¦ã‚‹ã‹ç¢ºèªç”¨ã«æœ«å°¾äº”è¡Œã‚’è¡¨ç¤º
    #print(df.tail(5))


    ####ãƒ‡ãƒ¼ã‚¿åŠ å·¥ã‚’ã—ã¦ã„ãã¾ã™ã€‚ä»Šå›ã¯ä¹–é›¢ç‡ã‚’å‡ºã—ãŸã„ã®ã§åˆ†è¶³ã®25MAã¨ãã®ä¹–é›¢ç‡ã‚’å‡ºã—ã¾ã™ã€‚
    #åŠ å·¥ã®ãŸã‚ã«å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã€åˆ—åã‚’å¤‰æ›´ã—ã€ãƒ‡ãƒ¼ã‚¿æŠœã‘ã‚’å‰Šé™¤ã—ãŸå¾Œã€ä»Šå›ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã ã‘ã«ã—ã¦ã„ã¾ã™
    df_copy = df.copy()
    df_copy.rename(columns={'datetime_jst': 'Date', 'open': 'Open',"high":"High","low":"Low",'close':'Close',"volume":"Volume"}, inplace=True)
    df_copy=df_copy.dropna()
    df2=df_copy.reindex(columns=["Date","Open","High","Low","Close","Volume"])

    #ç¢ºèªç”¨
    #print(pdr.tail(5))


    #ç§»å‹•å¹³å‡ç·šã¨ä¹–é›¢ç‡ã®è¨ˆç®—ã€€ã€€ã€€window=5ã€€ã‚’å¤‰æ›´ã™ã‚‹ã¨æœŸé–“ã‚’å¤‰ãˆã‚‰ã‚Œã¾ã™
    df2["sma25"] = df2["Close"].rolling(window=25).mean()
    #ä¹–é›¢ç‡è¨ˆç®—ã€€ï¼’ï¼•MAã§è¨ˆç®—ã—ã¦ã„ã¾ã™ã€€ï¼ˆMoving average deviation rateã€€ã®é ­æ–‡å­—ã§åˆ—åã¤ã‘ã¦ã¾ã™ï¼‰
    df2["MAER"] = (df2["Close"] - df2["sma25"]) / df2["sma25"] * 100
    df2['Date'] = pd.to_datetime(df2['Date'])

    #ä¹–é›¢ç‡ã®è²·ã„å ´ãƒ»å£²ã‚Šå ´ã®ä¹–é›¢ç‡ã‚’è¨ˆç®—ã—ã€è¡¨ç¤º
    m,s = df2["MAER"].mean(),df2["MAER"].std()
    deviation = (m-2*s)*-1/100
    lower = round((m-2*s),3)
    upper = round((m+2*s),3)

    df2["upper"] = df2["sma25"] + df2["sma25"] * deviation
    df2["lower"] = df2["sma25"] - df2["sma25"] * deviation

    return deviation , upper , lower, df2

@st.cache_data
def env_graph_show(df,chart_type,upper,lower):
    df2 = df.copy()
    import pandas as pd
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots

    # figã‚’å®šç¾©
    fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_width=[0.3,0.3, 0.6], x_title="Date")

    # Candlestick
    fig.add_trace(
        go.Candlestick(x=df2["Date"], open=df2["Open"], high=df2["High"], low=df2["Low"], close=df2["Close"], name="OHLC", showlegend=False),
        row=1, col=1)

    # Volume
    fig.add_trace(
        go.Bar(x=df2["Date"], y=df2["Volume"], name="Volume",marker_color='rgb(34, 42, 42)', showlegend=False),
        row=2, col=1)

    # MAER
    fig.add_trace(
        go.Scatter(x=df2["Date"], y=df2["MAER"], name="KRI",marker_color = "orange", showlegend=False),
        row=3, col=1
    )

    fig.add_trace(
        go.Scatter(x=[df2["Date"].iloc[0],df2["Date"].iloc[-1]], y=[lower,lower],mode="lines", name="-KRI",line = dict(color='red', width=1.5), showlegend=False),
        row=3, col=1
    )

    fig.add_trace(
        go.Scatter(x=[df2["Date"].iloc[0],df2["Date"].iloc[-1]], y=[upper,upper],mode="lines", name="+KRI",line = dict(color='red', width=1.5), showlegend=False),
        row=3, col=1
    )

    # SMA
    fig.add_trace(go.Scatter(x=df2["Date"], y=df2["sma25"], name="SMA25", mode="lines", line=dict(color="orange")), row=1, col=1)

    # Layout
    fig.update_layout(
        title={
            "text": chart_type +"ãƒãƒ£ãƒ¼ãƒˆ",
            "y":0.9,
            "x":0.5,
        },
        bargap=0
    )

    # ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—
    fig.add_trace(
        go.Scatter(x=df2["Date"], y=df2["upper"], name="ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—", line=dict(width=1, color="blue")),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(x=df2["Date"], y=df2["lower"], line=dict(width=1, color="blue"), showlegend=False),
        row=1, col=1
    )


    # yè»¸åã‚’å®šç¾©
    fig.update_yaxes(title_text="æ ªä¾¡", row=1, col=1)
    fig.update_yaxes(title_text="å‡ºæ¥é«˜", row=2, col=1)

    if chart_type == "1d":
        gap_resample = df2.resample("1D", on='Date').max()
        timegap = gap_resample[gap_resample["Open"].isnull()].index.to_list()

        fig.update_layout(
            xaxis=dict(
                rangeselector=dict(
                    buttons=list([
                        dict(count=1,
                            label="1ã‚«æœˆ",
                            step="month",
                            stepmode="backward"),
                        dict(count=6,
                            label="6ã‚«æœˆ",
                            step="month",
                            stepmode="backward"),
                        dict(count=1,
                            label="å¹´åˆæ¥",
                            step="year",
                            stepmode="todate"),
                        dict(count=1,
                            label="1å¹´",
                            step="year",
                            stepmode="backward"),
                        dict(step="all")
                    ])
                ),
                rangeslider=dict(
                    visible=False
                ),
                type="date"
            )
        )
        fig.update_xaxes(range = [df2["Date"].iloc[0],df2["Date"].iloc[-1]],rangebreaks=[dict(values= timegap)])

    else:#æ—¥è¶³ä»¥å¤–
        fig.update(layout_xaxis_rangeslider_visible=False)
        fig.update_xaxes(range = [df2["Date"].iloc[0],df2["Date"].iloc[-1]],rangebreaks=[
            dict(bounds=[15, 9], pattern="hour"),            # Remove non-trading hours
            dict(bounds=["sat", "mon"]),                        # Remove weekends
        ])

    #fig.show()
    return fig

@st.cache_data
def coding_process(_symbols,_N_list,_N_true):
    symbols = _symbols
    N_list = _N_list
    N_true = _N_true

    cols = {'æ¨™æº–åå·®': [],  'ç†æƒ³ä¹–é›¢ç‡ï¼šä¸Šé™(%)': [], 'ç†æƒ³ä¹–é›¢ç‡ï¼šä¸‹é™(%)': [],'ãƒ­ãƒ¼ã‚½ã‚¯è¶³æœ¬æ•°': []}
    df_dev = pd.DataFrame.from_dict(cols)# df
    dict_img = {}#å„figãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´

    coding_data = code_header.replace("symbols",str(symbols))

    #ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_text = "å‡¦ç†ä¸­"
    my_bar = st.progress(0, text=progress_text)

    percent_complete = 0.0
    for n in range(len(N_list)):

        if N_list[n] == "1min":
            if N_true[n] == True:
                deviation ,upper  , lower, df__ = cal_data_min(symbols,"1min")
                # dev_1min = deviation
                # upper_1min = upper
                # lower_1min = lower
                # df_1min = df__.copy()
                # df_dev.loc["1åˆ†è¶³"]=[dev_1min, upper_1min, lower_1min,int(len(df_1min))]
                # fig_1min = env_graph_show(df_1min)

                df_dev.loc["1åˆ†è¶³"]=[deviation, upper, lower,int(len(df__))]
                dict_img.update({N_list[n]:env_graph_show(df__,N_list[n],upper,lower)})
                coding_data = coding_data + code_1min.replace("upper_1min_data",str(upper)).replace("lower_1min_data",str(lower))
            else:
                pass

        if N_list[n] == "5min":
            if N_true[n] == True:
                deviation ,upper  , lower, df__ = cal_data_min(symbols,"5min")
                # dev_5min = deviation
                # upper_5min = upper
                # lower_5min = lower
                # df_5min = df__.copy()
                # df_dev.loc["5åˆ†è¶³"]=[dev_5min, upper_5min, lower_5min,int(len(df_5min))]
                # fig_5min = env_graph_show(df_5min)

                df_dev.loc["5åˆ†è¶³"]=[deviation, upper, lower,int(len(df__))]
                dict_img.update({N_list[n]:env_graph_show(df__,N_list[n],upper,lower)})

                coding_data = coding_data + code_5min.replace("upper_5min_data",str(upper)).replace("lower_5min_data",str(lower))
            else:
                pass


        if N_list[n] == "15min":
            if N_true[n] == True:
                deviation ,upper  , lower, df__ = cal_data_min(symbols,"15min")
                # dev_15min = deviation
                # upper_15min = upper
                # lower_15min = lower
                # df_15min = df__.copy()
                # df_dev.loc["15åˆ†è¶³"]=[dev_15min, upper_15min, lower_15min,int(len(df_15min))]
                # fig_15min = env_graph_show(df_15min)

                df_dev.loc["15åˆ†è¶³"]=[deviation, upper, lower,int(len(df__))]
                dict_img.update({N_list[n]:env_graph_show(df__,N_list[n],upper,lower)})

                coding_data = coding_data + code_15min.replace("upper_15min_data",str(upper)).replace("lower_15min_data",str(lower))
            else:
                pass

        if N_list[n] == "1hour":
            if N_true[n] == True:
                deviation ,upper  , lower, df__ = cal_data_min(symbols,"1hour")
                # dev_1hour = deviation
                # upper_1hour = upper
                # lower_1hour = lower
                # df_1hour = df__.copy()
                # fig_1hour = env_graph_show(df__,N_list[n],upper,lower)

                df_dev.loc["1æ™‚é–“è¶³"]=[deviation, upper, lower,int(len(df__))]
                dict_img.update({N_list[n]:env_graph_show(df__,N_list[n],upper,lower)})

                coding_data = coding_data + code_1hour.replace("upper_1hour_data",str(upper)).replace("lower_1hour_data",str(lower))
            else:
                pass

        if N_list[n] == "1d":
            if N_true[n] == True:
                deviation ,upper  , lower, df__ = cal_data_min(symbols,"1d")
                # dev_1d = deviation
                # upper_1d = upper
                # lower_1d = lower
                # df_1d = df__.copy()
                # fig_1d = env_graph_show(df__,N_list[n],upper,lower)

                df_dev.loc["æ—¥è¶³"]=[deviation, upper, lower,int(len(df__))]
                dict_img.update({N_list[n]:env_graph_show(df__,N_list[n],upper,lower)})
                coding_data = coding_data + code_1day.replace("upper_1day_data",str(upper)).replace("lower_1day_data",str(lower))

            else:
                pass

        percent_complete += 1/len(N_list)
        if percent_complete <= 1:
            my_bar.progress(percent_complete, text=progress_text)

    # df_dev_ = df_dev.style.format(precision=3).format(subset='ãƒ­ãƒ¼ã‚½ã‚¯è¶³æœ¬æ•°',precision=0).format(subset='æ¨™æº–åå·®',precision=5)
    coding_data = coding_data + code_Alert
    my_bar.empty()

    return dict_img, df_dev, coding_data

#plotlyã®ç™½é»’ã‚’ç›´ã™ã€‚
pio.templates.default = "plotly"


#github
st.set_page_config(layout="centered")

#codeææ–™
f = open("files/code_header.txt", 'r')
code_header = f.read()
f = open("files/code_1min.txt", 'r')
code_1min = f.read()
f = open("files/code_5min.txt", 'r')
code_5min = f.read()
f = open("files/code_15min.txt", 'r')
code_15min = f.read()
f = open("files/code_1hour.txt", 'r')
code_1hour = f.read()
f = open("files/code_1day.txt", 'r')
code_1day = f.read()
f = open("files/code_Alert.txt", 'r')
code_Alert = f.read()

#Google Colab
# f = open("code_header.txt", 'r')
# code_header = f.read()
# f = open("code_1min.txt", 'r')
# code_1min = f.read()
# f = open("code_5min.txt", 'r')
# code_5min = f.read()
# f = open("code_15min.txt", 'r')
# code_15min = f.read()
# f = open("code_1hour.txt", 'r')
# code_1hour = f.read()
# f = open("code_1day.txt", 'r')
# code_1day = f.read()
# f = open("code_Alert.txt", 'r')
# code_Alert = f.read()

st.markdown('<p style="font-family:ãƒ¡ã‚¤ãƒªã‚ª; font-size: 20px; font-weight: bold;">Trading Viewã®ç†æƒ³ä¹–é›¢ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ç”Ÿæˆã‚¢ãƒ—ãƒª</p>', unsafe_allow_html=True)


html_code = '''
<style type="text/css">
#QandA-1 {
	width: 100%;
	height: 1000px;
	overflow: auto;
	font-family: ãƒ¡ã‚¤ãƒªã‚ª;
	font-size: 14px;
    padding: 0 5px; /* å·¦å³ã«20pxã®ä½™ç™½ã‚’è¿½åŠ  */
	/* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ« */
	scrollbar-width: thin;
	scrollbar-color: rgba(155, 155, 155, 0.5) rgba(255, 255, 255, 0.1);
}
#QandA-1::-webkit-scrollbar {
	width: 12px;
}
#QandA-1::-webkit-scrollbar-track {
	background: rgba(255, 255, 255, 0.1);
}
#QandA-1::-webkit-scrollbar-thumb {
	background-color: rgba(155, 155, 155, 0.5);
	border-radius: 20px;
	border: 3px solid rgba(255, 255, 255, 0.1);
}
#QandA-1 h2 {

}
#QandA-1 dt {
	background: #444;
	color: #fff;
	padding: 8px;
	border-radius: 2px;
}
#QandA-1 dt:before {
	content: "ãƒ»";
	font-weight: bold;
	margin-right: 8px;
}
#QandA-1 dd {
	margin: 24px 16px 40px 32px;
	line-height: 140%;
	text-indent: -24px;
}
#QandA-1 dd:before {
	content: "ãƒ»";
	font-weight: bold;
	margin-right: 8px;
}
</style>


<div id="QandA-1">
	<h3>ã‚¢ãƒ—ãƒªã®èƒŒæ™¯</h3>
	<dl>
		<dt>ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã¨ã¯ï¼Ÿ</dt>
		<dd>ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã¯ã€ç§»å‹•å¹³å‡ç·šã‹ã‚‰ä¸€å®šã®å‰²åˆã§ä¸Šä¸‹ã«ã‚ªãƒ•ã‚»ãƒƒãƒˆã•ã›ãŸç·šã‚’è¡¨ç¤ºã™ã‚‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚’æŒ‡ã—ã¾ã™ã€‚
        <br>ã“ã‚Œã«ã‚ˆã‚Šã€æ ªä¾¡ãŒç§»å‹•å¹³å‡ç·šã‹ã‚‰ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã‚’è¦–è¦šçš„ã«æŠŠæ¡ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚
        <br>æ ªä¾¡ãŒç§»å‹•å¹³å‡ç·šã‹ã‚‰å¤§ããä¹–é›¢ã—ãŸå ´åˆã€æœ€çµ‚çš„ã«ã¯ç§»å‹•å¹³å‡ç·šã«æˆ»ã‚‹å‚¾å‘ãŒã‚ã‚‹ãŸã‚ã€ã“ã®ç‰¹æ€§ã‚’åˆ©ç”¨ã—ã¦æ ªä¾¡ã®åè»¢ãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ãŸã‚Šã€æ”¯æŒç·šã‚„æŠµæŠ—ç·šã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</dd>
		<dt>ç†æƒ³ãªä¹–é›¢ç‡ã¨ã¯ï¼Ÿ</dt>
		<dd>ä¹–é›¢ç‡ã¯éŠ˜æŸ„ã«ã‚ˆã£ã¦ç•°ãªã‚Šã€åŠ¹æœçš„ãªä¹–é›¢ç‡ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã¯é€šå¸¸ã€ç›®è¦–ã«ã‚ˆã‚‹ç¢ºèªãŒå¿…è¦ã§ã™ã€‚
        <br>ã¾ãŸæ ªä¾¡ã®ä¹–é›¢ã®ä»•æ–¹ã¯ä¸Šæ–¹ä¹–é›¢ã¨ä¸‹æ–¹ä¹–é›¢ã§ã¯å‚¾å‘ãŒç•°ãªã‚Šã¾ã™ãŒã€æ—¢å­˜ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã§ã¯ä¸Šä¸‹åŒã˜å€¤ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚
        <br>æœ¬ã‚¢ãƒ—ãƒªã§ã¯æ¨™æº–åå·®ï¼ˆÏƒï¼‰ã‚’ç”¨ã„ã¦ã€çµ±è¨ˆçš„ã«æ ªä¾¡åç™ºãŒæœŸå¾…ã§ãã‚‹ä¹–é›¢ç‡ã‚’ä¸Šé™å€¤ãƒ»ä¸‹é™å€¤åˆ¥ã€…ã«ç®—å‡ºã—ã¾ã™ã€‚</dd>
		<dt>ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ </dt>
		<dd>Trading Viewã¯è¤‡æ•°ã®æ™‚é–“è¶³ã‚’ä¸¦ã¹ã¦è¡¨ç¤ºã§ãã‚‹ãŸã‚ã€ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ (MTF)ã§æ ªä¾¡ã®åˆ†æãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚
        <br>ä¾‹ã¨ã—ã¦çŸ­æœŸè¶³ã§ã®ä¹–é›¢ãŒå¤§ããã¦ã‚‚ã€é•·æœŸè¶³ã§ã¯ãã‚Œã»ã©å¤§ããªä¹–é›¢ã§ã¯ãªã„ãªã©ãŒç¢ºèªã§ãã¾ã™ã€‚</dd>
	</dl>
    <h3><a href="https://jp.tradingview.com/?aff_id=127468" target="_blank" rel="noopener noreferrer">ã¾ã Trading Viewã®ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã£ã¦ã„ãªã„æ–¹ã¯ã“ã¡ã‚‰ã‹ã‚‰ã©ã†ãï¼</a></h3>
	<h3>æœ¬ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½</h3>
	<dl>
		<dt>â‘ Trading Viewã®ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®è‡ªå‹•ç”Ÿæˆ</dt>
		<dd>ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€å„æ™‚é–“è¶³ã§2Ïƒä»¥ä¸Šã®ä¹–é›¢ç‡ï¼ˆç™ºç”Ÿé »åº¦ãŒ4.5%æœªæº€ï¼‰ã‚’æŒã¤ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚
        <br>ç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã¯Trading Viewã«ç›´æ¥è²¼ã‚Šä»˜ã‘ã‚‹ã“ã¨ã§åˆ©ç”¨å¯èƒ½ã§ã€ã¾ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚‚å¯èƒ½ã§ã™ã€‚
        <br>ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾å¿œã—ã¦ãŠã‚Šã€è¡¨ç¤ºã®æ™‚é–“è¶³ãŒåˆ‡ã‚Šæ›¿ã‚ã‚‹ã¨è‡ªå‹•çš„ã«ä¸Šä¸‹é™ã®æ•°å€¤ãŒå¤‰ã‚ã‚‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã§ã™ã€‚ã¾ãŸã€ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã‚‚å¯èƒ½ã§ã™ã€‚</dd>
		<dt>â‘¡è¨­å®šå€¤ã«åˆ©ç”¨ã™ã‚‹ç†æƒ³çš„ãªä¹–é›¢ç‡ã¨è¨ˆç®—æ ¹æ‹ ã®ç¢ºèªãŒå¯èƒ½</dt>
		<dd>TradingViewã‚’åˆ©ç”¨ã—ãªã„å ´åˆã§ã‚‚ã€å„æ™‚é–“è¶³ã§ã®ç†æƒ³çš„ãªä¹–é›¢ç‡ã‚’ã¾ã¨ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
        <br>è¨ˆç®—ã«åˆ©ç”¨ã•ã‚Œã‚‹ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã®æœ¬æ•°ãŒå°‘ãªã„å ´åˆã€çµ±è¨ˆçš„ãªæœ‰æ„æ€§ãŒä½ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚ãã®ãŸã‚ã€è¨ˆç®—ã«åˆ©ç”¨ã•ã‚Œã‚‹ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã®æœ¬æ•°ã‚‚è¡¨ç¤ºã—ã¾ã™ã€‚
        <br>ãƒ‡ãƒ¼ã‚¿å–å¾—æœŸé–“ã®è¨­å®šï¼š1åˆ†è¶³=7æ—¥åˆ†,5åˆ†/15åˆ†è¶³=60æ—¥åˆ†,1æ™‚é–“è¶³=24ã‚«æœˆ,æ—¥è¶³=25å¹´
        <br>â€»éŠ˜æŸ„ã‚„é•·æœŸé€£ä¼‘ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚Šå–å¾—æœŸé–“ãŒçŸ­ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚</dd>
    	<dt>â‘£ãƒãƒ£ãƒ¼ãƒˆã‚¤ãƒ¡ãƒ¼ã‚¸ã®ç”Ÿæˆ</dt>
		<dd>Trading Viewã‚’åˆ©ç”¨ã—ãªã„å ´åˆã§ã‚‚ã€ã‚¢ãƒ—ãƒªå†…ã§ãƒãƒ£ãƒ¼ãƒˆã‚’ç¢ºèªã—ã€å®Ÿéš›ã®æ ªä¾¡å‹•å‘ã‚’ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚
        <br>ã‚¢ãƒ—ãƒªå†…ãƒãƒ£ãƒ¼ãƒˆã¯ä»»æ„ã«æ‹¡å¤§â‡”ç¸®å°ãŒå¯èƒ½ã§ã€ç”»åƒã¨ã—ã¦ä¿å­˜ã‚‚å¯èƒ½ã§ã™ã€‚</dd>

	</dl>
</div>
'''
stc.html(html_code,height=1200)
# st.write("ã¾ã Trading Viewã®ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã£ã¦ã„ãªã„æ–¹ã¯[ã“ã¡ã‚‰ã‹ã‚‰ã©ã†ãï¼](https://jp.tradingview.com/?aff_id=127468)")


# st.title("Trading Viewã®ç†æƒ³ä¹–é›¢ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ç”Ÿæˆã‚¢ãƒ—ãƒª")

# text = '''
# Trading Viewã§å„æ™‚é–“è¶³ã®ç§»å‹•å¹³å‡ä¹–é›¢ç‡ã‚’ç”¨ã„ãŸã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã‚ˆã†ã€‚

# ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã¯ã€ç§»å‹•å¹³å‡ç·šã‹ã‚‰ä¸Šä¸‹ã«ä¸€å®šã«ä¹–é›¢ã•ã›ãŸç·šã®ã“ã¨ã§ã€ç§»å‹•å¹³å‡ç·šã‹ã‚‰ã©ã‚Œãã‚‰ã„ä¹–é›¢ã—ã¦ã„ã‚‹ã®ã‹ã‚’ä¸€ç›®ã§ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
# ç§»å‹•å¹³å‡ç·šã‹ã‚‰ä¹–é›¢ã—ã™ããŸæ ªä¾¡ã¯æœ€çµ‚çš„ã«ã¯ç§»å‹•å¹³å‡ç·šã«åæŸã™ã‚‹ã¨ã„ã†ç‰¹æ€§ãŒã‚ã‚‹ã®ã§ã€ã“ã®ç‰¹æ€§ã‚’åˆ©ç”¨ã—ã¦åè»¢ã®ãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ãŸã‚Šã€æ”¯æŒç·šã‚„æŠµæŠ—ç·šã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

# ä¸€æ–¹ã€éŠ˜æŸ„ã«ã‚ˆã‚ŠåŠ¹æœçš„ãªä¹–é›¢ç‡ã¯ç•°ãªã‚Šã¾ã™ã€‚
# é€šå¸¸ã¯ç›®è¦–ã«ã‚ˆã£ã¦ä¹–é›¢ç‡ã‚’è¨­å®šã—ã¾ã™ãŒã€ã“ã“ã§ã¯çµ±è¨ˆçš„ã«åç™ºãŒæœŸå¾…ã§ãã‚‹ä¹–é›¢ç‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
# â€»æ¨™æº–åå·®ï¼ˆÏƒï¼‰ã‚’ç”¨ã„ãŸ2Ïƒ(ç´„95.5%ä»¥ä¸Šã®ä¹–é›¢)

# éŠ˜æŸ„æ¯ã«åŠ¹æœçš„ãªä¹–é›¢ç‡ã®ç®—å‡ºï¼‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®èª¿æ•´ã¯å¤§å¤‰ã§ã™ãŒã€
# ã“ã¡ã‚‰ã®ã‚¢ãƒ—ãƒªã§ç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã‚’Trading Viewã«è²¼ä»˜ã‘ã‚Œã°OKã€‚

# '''


# st.write(text)
# st.write("ã¾ã Trading Viewã®ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã£ã¦ã„ãªã„æ–¹ã¯[ã“ã¡ã‚‰ã‹ã‚‰ã©ã†ãï¼](https://jp.tradingview.com/?aff_id=127468)")


# Github
# https://www.jpx.co.jp/markets/statistics-equities/misc/01.html
url = 'https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls'
df_jpx = pd.read_excel(url)
df_jpx = df_jpx.iloc[:, [1, 2, 3, 9]]
database = df_jpx[df_jpx["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] != "ETFãƒ»ETN"]
database = database.astype(str)

# # Local
# url = "/content/drive/MyDrive/master_ColabNotebooks/kabu_files/test_account_files/230719 Env/data_j_202311.xls"
# df_jpx = pd.read_excel(url)
# df_jpx = df_jpx.iloc[:, [1, 2, 3, 9]]
# database = df_jpx[df_jpx["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] != "ETFãƒ»ETN"]
# database = database.astype(str)


# æŒ‡å®šã—ãŸéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¨æœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã‚’ã—ã¾ã™ã€‚
# symbols â†’ å€‹åˆ¥æ ªãƒ»æŒ‡æ•°ã®ã‚³ãƒ¼ãƒ‰

with st.form(key='form1'):
    st.cache_data.clear()

    input_txt = st.text_input('éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ› or éƒ¨åˆ†ä¸€è‡´ã®æ¤œç´¢', '8058')

    DB_result = database[(database['ã‚³ãƒ¼ãƒ‰'].str.contains(str(input_txt)))|(database['éŠ˜æŸ„å'].str.contains(str(input_txt)))]
    st.table(DB_result)
    if len(DB_result) == 0:
        st.write("ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“")
    if len(DB_result) > 1:
        st.write("1éŠ˜æŸ„ã«ãªã‚‹ã‚ˆã†ã«å…¥åŠ›ã—ã¦ãã ã•ã„")
    if len(DB_result) == 1:
        symbols = DB_result.iloc[0,0]
        name = DB_result.iloc[0,1]
        st.write(f"[ãƒ»TradingViewã§é–‹ã](https://jp.tradingview.com/chart/?symbol=TSE%3A{symbols})")
        st.write(f"[ãƒ»æ ªæ¢ã§ç¢ºèªã™ã‚‹](https://kabutan.jp/stock/chart?code={symbols})")

    st.write("ãƒ‡ãƒ¼ã‚¿ã®å¿…è¦ãªæ™‚é–“è¶³ï¼š")
    _1min = st.checkbox('1min')
    _5min = st.checkbox('5min',value=True)
    _15min = st.checkbox('15min')
    _1hour = st.checkbox('1hour')
    _1d = st.checkbox('1day',value=True)

    chart_radio = st.radio(label="ãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤º",options = ("ã‚¢ãƒ—ãƒªå†…ã§è¡¨ç¤º","Trading Viewã§ç¢ºèªã™ã‚‹ã€‚"),index=0,horizontal=True)
    if chart_radio == "ã‚¢ãƒ—ãƒªå†…ã§è¡¨ç¤º":
        st.warning("é¸æŠã—ã¦ã„ã‚‹æ™‚é–“è¶³ãŒå¤šã„ã¨ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã«æ™‚é–“ãŒæ›ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")

    st.warning("éŠ˜æŸ„ã‚’å¤‰æ›´ã—ãŸå ´åˆã€å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚’æŠ¼ã•ãªã„ã¨ãƒ‡ãƒ¼ã‚¿ãŒåæ˜ ã•ã‚Œã¾ã›ã‚“ã€‚")
    submit = st.form_submit_button("å®Ÿè¡Œ")

if submit:
    st.session_state.submitted = True
    N_list = ["1min","5min","15min","1hour","1d"]
    N_true = [_1min, _5min, _15min, _1hour, _1d]

    dict_img,df_dev,coding_data = coding_process(symbols,N_list,N_true)

if 'submitted' in st.session_state:
    N_list = ["1min","5min","15min","1hour","1d"]
    N_true = [_1min, _5min, _15min, _1hour, _1d]

    #if st.session_state.value == 0:
    #st.write("if st.session_state.value == 0,start")
    #dict_img,df_dev,coding_data = coding_process(symbols,N_list,N_true)
    #st.session_state.value = 1

    #st.write(st.session_state.value)

    #if st.session_state.value == 1:

    dict_img,df_dev,coding_data = coding_process(symbols,N_list,N_true)

    #ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    if chart_radio == "ã‚¢ãƒ—ãƒªå†…ã§è¡¨ç¤º":
        progress_text = "å‡¦ç†ä¸­"
        my_bar = st.progress(0, text=progress_text)
        percent_complete = 0.0
        with st.expander("ãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤ºğŸ“ˆ", expanded=False):
            st.write("æ‹¡å¤§ç¸®å°ãªã©ä»»æ„ã®ä½ç½®ã§ä¿å­˜å¯èƒ½ã§ã™ï¼šğŸ“·")
            for mykey, myvalue in dict_img.items():

                st.write("æ™‚é–“è¶³ï¼š",mykey)
                st.plotly_chart(myvalue, use_container_width=True)

                percent_complete += 1/len(N_list)
                if percent_complete <= 1:
                    my_bar.progress(percent_complete, text=progress_text)
            my_bar.empty()

    df_dev_ = df_dev.style.format(precision=3).format(subset='ãƒ­ãƒ¼ã‚½ã‚¯è¶³æœ¬æ•°',precision=0).format(subset='æ¨™æº–åå·®',precision=5)
    st.write(df_dev_)
    df_filename =  "EnvCode_" +symbols + "_" + name + ".csv"
    csv_ = df_dev.to_csv().encode('cp932')
    st.download_button(label="è¡¨ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data = csv_, file_name = df_filename,mime='text/csv')

    st.write("Pineã‚³ãƒ¼ãƒ‰:" + symbols + " " + name)
    code_filename =  "EnvCode_" +symbols + "_" + name + ".txt"
    st.download_button(label="ã‚³ãƒ¼ãƒ‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",file_name = code_filename, data = coding_data,mime="text/plain")
    st.code(coding_data)

    #â‘ dataéƒ¨åˆ†ã‚’ä½œæˆ(stackã§å¿…è¦æƒ…å ±ã‚’1è¡Œã«ã¾ã¨ã‚ã‚‹ã€‚)/indexã‚’0ã¨ã—ã¦concatã§çµåˆ
    #â‘¡multiindexã‚’ä½œæˆï¼ˆæœ€çµ‚çš„ã«ã¯colï¼‰
    #â‘¢data,multiindexã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œã‚‹ã€‚
    #â‘£indexåã‚’dateã«å¤‰æ›´ã™ã‚‹ã€‚

    ###â‘ dataéƒ¨åˆ†ã‚’ä½œæˆ###
    df_dev_stack = pd.DataFrame(df_dev.stack()).T
    date = datetime.datetime.now().date()
    ds1 = pd.DataFrame([symbols,name],index=['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰','éŠ˜æŸ„å']).T
    ds2 = pd.DataFrame(df_dev.stack()).T
    ds = pd.concat([ds1,ds2],axis=1)

    ###â‘¡multiindexã‚’ä½œæˆï¼ˆæœ€çµ‚çš„ã«ã¯colï¼‰###
    col11=['éŠ˜æŸ„','éŠ˜æŸ„']
    col12=['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰','éŠ˜æŸ„å']
    col21=df_dev.stack().reset_index()["level_0"].tolist()
    col22=df_dev.stack().reset_index()["level_1"].tolist()

    multicol1 = col11+col21
    multicol2 = col12+col22
    df_multicols = pd.DataFrame([multicol1,multicol2]).T
    mult_index = pd.MultiIndex.from_frame(df_multicols)

    ###â‘¢data,multiindexã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œã‚‹ã€‚###
    ###â‘£indexåã‚’dateã«å¤‰æ›´ã™ã‚‹ã€‚###
    df_one_data = pd.DataFrame(data=ds.iloc[0].tolist(),index = mult_index).T.rename(index= {0:date})

    ####gsheetã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—###
    ##https://qiita.com/moomin_moomin/items/bc7a2250313549b2e115
    ##https://docs.streamlit.io/knowledge-base/tutorials/databases/gcs
    ##https://teratail.com/questions/ay01ga5mm9tpye
    ##å…±æœ‰è¨­å®šå¾Œã«urlã®æœ«å°¾ã«/edit?usp=sharingã‚’ã¤ã‘ã‚‹ã€‚
    url = "https://docs.google.com/spreadsheets/d/1vXaglvGGbGN0pc8vEjiA7bCPpPTacFxvLGm3iKRVVUw//edit?usp=sharing"

    # ã“ã£ã¡ã§å‹•ä½œ
    #conn = st.experimental_connection("gsheets", type=GSheetsConnection) 

    # ã“ã£ã¡ã§ModuleNotFoundError: No module named 'streamlit_gsheets'ãŒç™ºç”Ÿ
    #æ›¸ãè¾¼ã¿ç”¨
    gsheet_connector = connect_to_gsheet()
    
    #èª­ã¿å–ã‚Šã ã‘ã®ã‚‚ã®
    conn = st.connection("gsheets", type=GSheetsConnection) 
    df_all_old = conn.read(spreadsheet=url,index_col=0,header=[0,1])

    ##éå»ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
    #df_all_old = pd.read_csv("files/history.csv",index_col=0, header=[0, 1],encoding = "cp932")
    if df_all_old.iloc[-1].tolist() != df_one_data.iloc[-1].tolist():
        df_all_new = pd.concat([df_all_old,df_one_data],axis=0)
        
        overwrite_gsheet_with_df(gsheet_connector, df_all_new)
    else:
        df_all_new = df_all_old.copy()

    st.write(df_all_new)